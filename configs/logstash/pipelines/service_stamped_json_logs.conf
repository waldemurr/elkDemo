# Логи будут прилетать из beats'ов по порту 5044
input {
  beats {
    port => 5044
  }
  tcp {
    host => "0.0.0.0"
    port => "${LOGSTASH_PORT_TCP}"
    type => syslog
    codec => json_lines
    tcp_keep_alive=>true
  }
  # udp {
  #   host => "0.0.0.0"
  #   port => "${LOGSTASH_PORT}"
  #   type => syslog
  #   codec => json_lines
  # }
}

# filter {
#   # Дропаем лог, если он пришел от неизвестного нам сервиса (по желанию)
#   # Ниже я два раза указал host_metrics_app в списке - это не опечатка. Какого-то лешего в условии, в массиве должно быть минимум 2 элемента.
#   # Так как приложение у нас одно - просто дублируем
#   # Поле service у нас появится благодаря конфигурированию Filebeat
#   if [fields][service] not in ["host_metrics_app", "host_metrics_app"] {
#     drop {}
#   }
#   # Оригинальный json-лог, который был сгенерирован вашим приложением, будет лежать по ключу message
#   # (из filebeat'а логи прилетают не в чистом виде)
#   json {
#     source => "message"
#   }
#   # Говорим logstash'у, чтобы в качестве timestamp'а лога он брал именно наш timestamp
#   # (в моем случае поле asctime в теле сообщения в формате "yyyy-MM-dd HH:mm:ss.SSS" и часовом поясе UTC)
#   # и затем подтирал поле asctime.
#   date {
#     match => ["asctime", "yyyy-MM-dd HH:mm:ss.SSS"]
#     timezone => "UTC"
#     target => "@timestamp"
#     remove_field => ["asctime"]
#   }
# }

output {
  # Отображаем лог в stdout (поиграйтесь и удалите данную строку)
  stdout {}
  # Пушим лог в elasticsearch, индекс будет создан автоматически по названию сервиса и текущей дате
  elasticsearch {
    hosts => "${ELASTIC_HOSTS}"
    index => "logs_%{[fields][service]}-%{+YYYY.MM.dd}"
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    cacert=> "certs/ca/ca.crt"
  }
}